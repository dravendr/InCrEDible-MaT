{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afc41c1d",
   "metadata": {},
   "source": [
    "# Train ANN Model Alkaline ORR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9aaee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sklearn\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import ExtraTreeRegressor\n",
    "from sklearn import svm\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr, spearmanr, kendalltau\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import pandas as pd\n",
    "#%matplotlib \n",
    "###########import packages##########\n",
    "import catboost\n",
    "import xgboost\n",
    "import lightgbm\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import *\n",
    "import pickle\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import  *\n",
    "###########import packages##########\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import optimizers\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.constraints import max_norm\n",
    "from keras.models import Sequential \n",
    "from keras.layers import Dense \n",
    "from keras.layers import Dropout \n",
    "from keras.models import Model\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.wrappers.scikit_learn import KerasClassifier \n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.constraints import maxnorm \n",
    "# from keras.wrappers import scikit_learn\n",
    "from scikeras.wrappers import KerasClassifier, KerasRegressor\n",
    "###########loading data##########\n",
    "loo = LeaveOneOut()\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5002788c",
   "metadata": {},
   "source": [
    "# ANN needs scalers to regularize input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a5a7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "Minmaxsc  = MinMaxScaler(feature_range=(0, 1))\n",
    "Minmaxsc2  = MinMaxScaler(feature_range=(0, 1))\n",
    "Stdsc  = StandardScaler()\n",
    "Stdsc2  = StandardScaler()\n",
    "MAsc  = MaxAbsScaler()\n",
    "MAsc2  = MaxAbsScaler()\n",
    "Rsc  = RobustScaler()\n",
    "Rsc2  = RobustScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ba61d7",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efb8163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, accuracy_score, precision_score, recall_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "def compute_classification_metrics(y_true, y_pred, y_pred_proba, average_method='macro', multi_class_method='ovo'):\n",
    "\n",
    "    if len(y_true.shape) > 1:  # Check if it's a multi-class problem\n",
    "        auc = roc_auc_score(y_true, y_pred_proba, average=average_method, multi_class=multi_class_method)\n",
    "    else:\n",
    "        auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "\n",
    "    f1 = f1_score(y_true, y_pred, average=average_method)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average=average_method)\n",
    "    recall = recall_score(y_true, y_pred, average=average_method)\n",
    "    print(f'AUC: {auc}, F1 Score: {f1}, Accuracy: {acc}, Precision: {precision}, Recall: {recall}')\n",
    "    return auc,f1,acc,precision,recall\n",
    "def plot_roc_curve(y_train, y_pred_train, y_test, y_pred_test, title):\n",
    "    fig, ax = plt.subplots()  # This creates a new figure and axes\n",
    "\n",
    "    for data, label, dataset in [(y_train, y_pred_train, 'Train'), (y_test, y_pred_test, 'Test')]:\n",
    "        if len(data.shape) > 1:  # Check if it's a multi-class problem\n",
    "            fpr = dict()\n",
    "            tpr = dict()\n",
    "            roc_auc = dict()\n",
    "            for i in range(data.shape[1]):\n",
    "                fpr[i], tpr[i], _ = roc_curve(data.iloc[:, i], label[:, i])\n",
    "                roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "            \n",
    "            for i in range(data.shape[1]):\n",
    "                ax.plot(fpr[i], tpr[i], label=f'ROC curve of {dataset} class {i} (area = {roc_auc[i]:.2f})')\n",
    "        else:\n",
    "            # Assuming the second column of label array represents the positive class probabilities\n",
    "            fpr, tpr, _ = roc_curve(data, label[:, 1])\n",
    "            roc_auc = auc(fpr, tpr)\n",
    "            ax.plot(fpr, tpr, label=f'{dataset} ROC curve (area = {roc_auc:.2f})')\n",
    "\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title(f'ROC Curve - {title}')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return fig, ax  # Return the Figure and Axes\n",
    "\n",
    "\n",
    "def gridsearch(model,param,algorithm_name,X,y):\n",
    "    # For binary classification, you could use 'accuracy' or 'f1' as a scoring method\n",
    "    # For multi-class classification, you might want to use 'accuracy' or 'f1_macro'\n",
    "    grid = GridSearchCV(model,param_grid=param,scoring='accuracy',cv=5,n_jobs=-1,verbose=2)\n",
    "    grid.fit(X,y)\n",
    "    best_model=grid.best_estimator_\n",
    "    best_score=grid.best_score_\n",
    "    print('Best Classifier:',grid.best_params_,'Best Score:', best_score)\n",
    "    return best_model,best_score\n",
    "seed=283"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec05e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "def predict_print_plot(data_input, data_output, algorithm_name, model, random_seed):\n",
    "    # Prepare train and test data\n",
    "    data_input_train, data_input_test, data_output_train, data_output_test = train_test_split(data_input, data_output, test_size=0.05, random_state=random_seed,stratify=data_output)\n",
    "\n",
    "    # Predict labels for all data, train data, and test data\n",
    "    y_pred_all = model.predict(data_input)\n",
    "    y_pred_train = model.predict(data_input_train)\n",
    "    y_pred_test = model.predict(data_input_test)\n",
    "\n",
    "    # Predict probabilities for all data, train data, and test data\n",
    "    y_pred_proba_all = model.predict_proba(data_input)\n",
    "    y_pred_proba_train = model.predict_proba(data_input_train)\n",
    "    y_pred_proba_test = model.predict_proba(data_input_test)\n",
    "    \n",
    "    # Print metrics\n",
    "    print('Metrics for All Data:')\n",
    "    all_perf=compute_classification_metrics(data_output, y_pred_all, y_pred_proba_all)\n",
    "    print('Metrics for Test Data:')\n",
    "    test_perf=compute_classification_metrics(data_output_test, y_pred_test, y_pred_proba_test)\n",
    "    print('Metrics for Train Data:')\n",
    "    train_perf=compute_classification_metrics(data_output_train, y_pred_train, y_pred_proba_train)\n",
    "\n",
    "    # Plot ROC curve for both train and test data\n",
    "    fig,ax=plot_roc_curve(data_output_train, y_pred_proba_train, data_output_test, y_pred_proba_test, title=algorithm_name)\n",
    "    return fig,ax,test_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5159ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ANN_model_3layer(X, learning_rate, num_classes, regular_term=0.001, neuron_number=25, drop_out_rate=0.1):\n",
    "    regularizer=keras.regularizers.l2(regular_term)\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neuron_number, input_dim=X.shape[1], kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))    \n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    \n",
    "    # The number of nodes in the last layer depends on the number of classes\n",
    "    if num_classes == 2: # binary classification\n",
    "        model.add(Dense(1, activation='sigmoid'))  \n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "    else: # multi-class classification\n",
    "        model.add(Dense(num_classes, activation='softmax'))  \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aacf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "database=pd.read_csv('processed_database.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0276c13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_output_full=database.iloc[:,1]\n",
    "data_input_full=database.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e4f879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data_output_full_l\n",
    "data_output_full_l = data_output_full.map(lambda x: 0 if x < 0.83 else 1)\n",
    "# Create data_output_full_m\n",
    "data_output_full_m = data_output_full.map(lambda x: 0 if x < 0.88 else 1)\n",
    "# Create data_output_full_h\n",
    "data_output_full_h = data_output_full.map(lambda x: 0 if x < 0.93 else 1)\n",
    "# Create data_output_full_multi\n",
    "data_output_full_multi = np.where(data_output_full < 0.83, 0, np.where(data_output_full > 0.93, 2, 1))\n",
    "data_output_full_multi_encoded = pd.get_dummies(data_output_full_multi, prefix='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf70741",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_full_ANN=Stdsc.fit_transform(data_input_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6206e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def predict_and_print_cv(data_output,model,n_splits=5):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "    results_all, results_test, results_train = [], [], []\n",
    "\n",
    "    for train_index, test_index in kfold.split(data_input_full_ANN):\n",
    "        X_train, X_test = data_input_full_ANN[train_index], data_input_full_ANN[test_index]\n",
    "        if len(data_output.shape)>1:\n",
    "            y_train, y_test = data_output.iloc[train_index], data_output.iloc[test_index]\n",
    "        else:\n",
    "            y_train, y_test = data_output[train_index], data_output[test_index]\n",
    "        model.fit(X_train, y_train)  \n",
    "\n",
    "        pred_train = model.predict(X_train)\n",
    "        pred_test = model.predict(X_test)\n",
    "\n",
    "        real_train = y_train\n",
    "        real_test = y_test\n",
    "\n",
    "        pred_all = model.predict(data_input_full_ANN)\n",
    "        real_all = data_output\n",
    "        \n",
    "        y_pred_proba_all = model.predict_proba(data_input_full_ANN)\n",
    "        y_pred_proba_train = model.predict_proba(X_train)\n",
    "        y_pred_proba_test = model.predict_proba(X_test)\n",
    "        \n",
    "        \n",
    "        results_all.append(compute_classification_metrics(real_all, pred_all,y_pred_proba_all))\n",
    "        results_test.append(compute_classification_metrics(real_test, pred_test,y_pred_proba_test))\n",
    "        results_train.append(compute_classification_metrics(real_train, pred_train,y_pred_proba_train))\n",
    "\n",
    "    # Compute average metrics over all folds\n",
    "    avg_results_all = np.mean(results_all, axis=0)\n",
    "    avg_results_test = np.mean(results_test, axis=0)\n",
    "    avg_results_train = np.mean(results_train, axis=0)\n",
    "\n",
    "    print(\"Average metrics over all data: \", avg_results_all)\n",
    "    print(\"Average metrics over test data: \", avg_results_test)\n",
    "    print(\"Average metrics over train data: \", avg_results_train)\n",
    "\n",
    "    return avg_results_all, avg_results_test, avg_results_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a6b234",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_list = [16,32,64]\n",
    "optimizers_list=['adam','sgd']\n",
    "epochs_list=[25,50,75]\n",
    "param_ann = dict(batch_size=batch_size_list, \n",
    "                 epochs=epochs_list,\n",
    "                optimizer=optimizers_list\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d26c3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ['PYTHONHASHSEED']=str(1)\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "tf.compat.v1.set_random_seed(1)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "def train_model(data_output,task_type,seed):\n",
    "    if len(data_output.shape)>1:\n",
    "        num_classes = data_output.shape[1] # Number of columns in the encoded DataFrame\n",
    "    else:\n",
    "        num_classes = data_output.nunique() # Number of columns in the encoded DataFrame\n",
    "    model_ANNClassifier = KerasClassifier(build_fn=create_ANN_model_3layer(X=data_input_full,num_classes=num_classes,learning_rate=0.001), verbose=0)\n",
    "    X_train_ANN,X_test_ANN,y_train_ANN,y_test_ANN=train_test_split(data_input_full_ANN,data_output,test_size=0.05,random_state=seed,stratify=data_output)\n",
    "    ANN_3layer,ANN_3layer_score=gridsearch(model_ANNClassifier,param_ann,'Artificial Neural Network_3layer',X_train_ANN,y_train_ANN)\n",
    "    fig,ax,test_perf=predict_print_plot(data_input_full_ANN,data_output,task_type,ANN_3layer,seed)\n",
    "    return ANN_3layer,fig,test_perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfb3ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.models import load_model\n",
    "for seed in range(1,100):\n",
    "    if not os.path.exists(str(seed) + \"_th_seed\"):\n",
    "        os.makedirs(str(seed) + \"_th_seed\")    \n",
    "    print('low')\n",
    "    ANN_model_l,fig_l,perf_l=train_model(data_output_full_l,'Lenient',seed)\n",
    "    # Save the model and the figure\n",
    "    ANN_model_l.model_.save(os.path.join(str(seed) + \"_th_seed\", 'ANN_model_l.h5'))\n",
    "    fig_l.savefig(os.path.join(str(seed) + \"_th_seed\", 'fig_l.png'))\n",
    "    \n",
    "    print('middle')\n",
    "    ANN_model_m,fig_m,perf_m=train_model(data_output_full_m,'Moderate',seed)\n",
    "    # Save the model and the figure\n",
    "    ANN_model_m.model_.save(os.path.join(str(seed) + \"_th_seed\", 'ANN_model_m.h5'))\n",
    "    fig_m.savefig(os.path.join(str(seed) + \"_th_seed\", 'fig_m.png'))\n",
    "    \n",
    "    print('high')\n",
    "    ANN_model_h,fig_h,perf_h=train_model(data_output_full_h,'Strict',seed)\n",
    "    # Save the model and the figure\n",
    "    ANN_model_h.model_.save(os.path.join(str(seed) + \"_th_seed\", 'ANN_model_h.h5'))\n",
    "    fig_h.savefig(os.path.join(str(seed) + \"_th_seed\", 'fig_h.png'))\n",
    "    \n",
    "    print('multi')\n",
    "    ANN_model_multi,fig_multi,perf_multi=train_model(data_output_full_multi_encoded,'Multi-Class',seed)\n",
    "    # Save the model and the figure\n",
    "    ANN_model_multi.model_.save(os.path.join(str(seed) + \"_th_seed\", 'ANN_model_multi.h5'))\n",
    "    fig_multi.savefig(os.path.join(str(seed) + \"_th_seed\", 'fig_multi.png'))\n",
    "\n",
    "    average_tuple = tuple(sum(t) / len(t) for t in zip(perf_l, perf_m, perf_h, perf_multi))\n",
    "\n",
    "    print('seed is',seed,'average perf:',average_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e236ad16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ANN_model_3layer_cv_adam(X, learning_rate, num_classes, regular_term=0.001, neuron_number=25, drop_out_rate=0.1):\n",
    "    regularizer=keras.regularizers.l2(regular_term)\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neuron_number, input_dim=X.shape[1], kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))    \n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    \n",
    "    # The number of nodes in the last layer depends on the number of classes\n",
    "    if num_classes == 2: # binary classification\n",
    "        model.add(Dense(1, activation='sigmoid'))  \n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "    else: # multi-class classification\n",
    "        model.add(Dense(num_classes, activation='softmax'))  \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adam(learning_rate), metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "def create_ANN_model_3layer_cv_sgd(X, learning_rate, num_classes, regular_term=0.001, neuron_number=25, drop_out_rate=0.1):\n",
    "    regularizer=keras.regularizers.l2(regular_term)\n",
    "    model = Sequential() \n",
    "    model.add(Dense(neuron_number, input_dim=X.shape[1], kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))    \n",
    "    model.add(Dense(neuron_number, input_dim=neuron_number, kernel_initializer='random_normal',\n",
    "                    bias_initializer='random_normal',activation='relu',kernel_regularizer=regularizer)) \n",
    "    model.add(Dropout(drop_out_rate))\n",
    "    \n",
    "    # The number of nodes in the last layer depends on the number of classes\n",
    "    if num_classes == 2: # binary classification\n",
    "        model.add(Dense(1, activation='sigmoid'))  \n",
    "        model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(learning_rate), metrics=['accuracy'])\n",
    "    else: # multi-class classification\n",
    "        model.add(Dense(num_classes, activation='softmax'))  \n",
    "        model.compile(loss='categorical_crossentropy', optimizer=optimizers.SGD(learning_rate), metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e6c635",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the function for getting CV average metrics\n",
    "num_classes=2\n",
    "model_ANNClassifier_CV = KerasClassifier(build_fn=create_ANN_model_3layer_cv_adam(X=data_input_full,num_classes=num_classes,learning_rate=0.001), batch_size=64, epochs=25, verbose=0)\n",
    "avg_results_all_l, avg_results_test_l, avg_results_train_l = predict_and_print_cv(data_output_full_l,model_ANNClassifier_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcc5a48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the function for getting CV average metrics\n",
    "num_classes=2\n",
    "model_ANNClassifier_CV = KerasClassifier(build_fn=create_ANN_model_3layer_cv_adam(X=data_input_full,num_classes=num_classes,learning_rate=0.001),batch_size=64, epochs=75, verbose=0)\n",
    "avg_results_all_m, avg_results_test_m, avg_results_train_m = predict_and_print_cv(data_output_full_m,model_ANNClassifier_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e9d882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the function for getting CV average metrics\n",
    "num_classes=2\n",
    "model_ANNClassifier_CV = KerasClassifier(build_fn=create_ANN_model_3layer_cv_adam(X=data_input_full,num_classes=num_classes,learning_rate=0.001),batch_size=64, epochs=25, verbose=0)\n",
    "avg_results_all_h, avg_results_test_h, avg_results_train_h = predict_and_print_cv(data_output_full_h,model_ANNClassifier_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bbd866",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the function for getting CV average metrics\n",
    "num_classes=3\n",
    "model_ANNClassifier_CV = KerasClassifier(build_fn=create_ANN_model_3layer_cv_adam(X=data_input_full,num_classes=num_classes,learning_rate=0.001),batch_size=64, epochs=25, verbose=0)\n",
    "avg_results_all_multi, avg_results_test_multi, avg_results_train_multi = predict_and_print_cv(data_output_full_multi_encoded,model_ANNClassifier_CV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c881fc7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
