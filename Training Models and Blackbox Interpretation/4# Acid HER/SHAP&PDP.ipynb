{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97f10fbc",
   "metadata": {},
   "source": [
    "# SHAP Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266aaadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import pandas as pd\n",
    "import keras\n",
    "from sklearn.preprocessing import *\n",
    "import numpy as np\n",
    "Minmaxsc  = MinMaxScaler(feature_range=(0, 1))\n",
    "Minmaxsc2  = MinMaxScaler(feature_range=(0, 1))\n",
    "Stdsc  = StandardScaler()\n",
    "Stdsc2  = StandardScaler()\n",
    "MAsc  = MaxAbsScaler()\n",
    "MAsc2  = MaxAbsScaler()\n",
    "Rsc  = RobustScaler()\n",
    "Rsc2  = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183c9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "database=pd.read_csv('processed_database.csv')\n",
    "data_output_full=database.iloc[:,1]\n",
    "data_input_full=database.iloc[:,2:]\n",
    "data_input_full_ANN=Stdsc.fit_transform(data_input_full)\n",
    "data_output_full_ANN=Stdsc2.fit_transform(np.array(data_output_full).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac4bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_full_ANN_for_shap=pd.DataFrame(data_input_full_ANN,columns=data_input_full.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a863ea20",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=keras.models.load_model(\"Acid_HER.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3409aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "from sklearn.utils.validation import check_is_fitted\n",
    "\n",
    "# Define a new class that inherits from sklearn's base estimator classes.\n",
    "class KerasPDPWrapper(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.fitted_ = True  # Indicate that the model is already fitted\n",
    "    def fit(self, X, y=None):\n",
    "        # Do nothing, the model is already trained\n",
    "        return self\n",
    "    def predict(self, X, y=None):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Create an instance of the wrapper with the Keras model.\n",
    "PDP_model = load_model(\"Acid_HER.h5\")\n",
    "PDP_wrapped_model = KerasPDPWrapper(PDP_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f9780f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute SHAP values\n",
    "explainer = shap.Explainer(model, data_input_full_ANN)\n",
    "shap_values = explainer(data_input_full_ANN_for_shap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4384253a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values from the 64th feature onwards\n",
    "sliced_values = shap_values.values[:, 64:]\n",
    "\n",
    "# Create a new Explanation object with the sliced values\n",
    "sliced_shap_values = shap.Explanation(values=sliced_values, data=shap_values.data[:, 64:], feature_names=shap_values.feature_names[64:])\n",
    "\n",
    "# Calculate the absolute mean\n",
    "cohorts = sliced_shap_values.cohorts(2).abs.mean(0)\n",
    "\n",
    "# Create the bar plot\n",
    "shap.plots.bar(cohorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d826986e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,64:],feature_names=list(data_input_full.columns)[64:],max_display=13,alpha=0.5,plot_size=[6,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b442b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values[:,64:],feature_names=list(data_input_full.columns)[64:],max_display=100,alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012d7b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# shap.summary_plot(shap_values[:,64:],feature_names=list(data_input_full.columns)[64:],max_display=15,alpha=0.5)\n",
    "shap.plots.heatmap(shap_values[:,64:],max_display=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca5fd3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot('Judge_Nanoparticles',shap_values.values,data_input_full,interaction_index='Judge_heterostructures',alpha=0.5)\n",
    "# Plot the partial dependence.\n",
    "plot_partial_dependence(PDP_wrapped_model, data_input_full, [('Judge_Nanoparticles','Judge_heterostructures')],grid_resolution=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fab706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shap.dependence_plot('Judge_3D',shap_values.values,data_input_full,interaction_index='Judge_alloy',alpha=0.5)\n",
    "# Plot the partial dependence.\n",
    "plot_partial_dependence(PDP_wrapped_model, data_input_full, [('Judge_3D','Judge_alloy')], grid_resolution=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d1d00e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#####clustered plot#####\n",
    "clustering = shap.utils.hclust(data_input_full_ANN, data_output_full_ANN) \n",
    "shap.plots.bar(shap_values, max_display=15,clustering=clustering,clustering_cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c072355e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import partial_dependence\n",
    "def compute_pdp_importances(model, X):\n",
    "    pdp_importances = []\n",
    "    for feature_idx in range(X.shape[1]):\n",
    "        pdp_results, _ = partial_dependence(model, X, [feature_idx], grid_resolution=50)\n",
    "        pdp_range = np.max(pdp_results) - np.min(pdp_results)\n",
    "        pdp_importances.append(pdp_range)\n",
    "    return np.array(pdp_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9310464a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Compute PDP importances\n",
    "pdp_importances = compute_pdp_importances(PDP_wrapped_model, data_input_full_ANN_for_shap)\n",
    "\n",
    "# Create a DataFrame to pair importances with feature names\n",
    "importances_df = pd.DataFrame({\n",
    "    'feature': data_input_full_ANN_for_shap.columns,\n",
    "    'importance': pdp_importances\n",
    "})\n",
    "\n",
    "# Filter for only features after the 64th\n",
    "importances_df = importances_df.iloc[64:]\n",
    "\n",
    "# Sort importances\n",
    "importances_df = importances_df.sort_values(by='importance')\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(9, 18))\n",
    "plt.barh(range(importances_df.shape[0]), importances_df['importance'])\n",
    "plt.yticks(range(importances_df.shape[0]), importances_df['feature'])\n",
    "plt.xlabel('Partial Dependence Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b023ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
