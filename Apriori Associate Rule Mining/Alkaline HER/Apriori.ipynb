{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5861cb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87779dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_replace(input_database,high_low,bar):\n",
    "    database=input_database.copy(deep=True)\n",
    "    for i in range(0,len(database)):\n",
    "        if high_low=='high':\n",
    "            if database.iloc[i,0]>=bar:\n",
    "                database.iloc[i,0]='Qualified'\n",
    "            else:\n",
    "                database.iloc[i,0]='Not_Qualified'\n",
    "        else:\n",
    "            if database.iloc[i,0]<=bar:\n",
    "                database.iloc[i,0]='Qualified'\n",
    "            else:\n",
    "                database.iloc[i,0]='Not_Qualified'\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49c7d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def material_replace(database,start,finish):\n",
    "    for i in range (start,finish):\n",
    "        for j in range(0,len(database)):\n",
    "            if database.iloc[j,i]==1:\n",
    "                database.iloc[j,i]=list(database.columns)[i]+'_True'\n",
    "            else:\n",
    "                database.iloc[j,i]=list(database.columns)[i]+'_False'\n",
    "    return database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cf5618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inspect(output):\n",
    "    lhs = [tuple(result[2][0][0])[0] for result in output]\n",
    "    rhs = [tuple(result[2][0][1])[0] for result in output]\n",
    "    support = [result[1] for result in output]\n",
    "    confidence = [result[2][0][2] for result in output]\n",
    "    lift = [result[2][0][3] for result in output]\n",
    "    return list(zip(lhs, rhs, support, confidence, lift))\n",
    "def inspect_3(output):\n",
    "    return_list=[]\n",
    "    for result in output:\n",
    "        for i in range(0,3):\n",
    "            try:\n",
    "                lhs = tuple(result[2][i][0])\n",
    "                rhs = tuple(result[2][i][1])\n",
    "                support = result[1]\n",
    "                confidence = result[2][i][2]\n",
    "                lift = result[2][i][3]\n",
    "                return_list.append(tuple([lhs, rhs, support, confidence,lift]))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "    return return_list\n",
    "def find_qualified_2(output_DataFrame):\n",
    "    new_df=pd.DataFrame(columns = ['Left_Hand_Side', 'Right_Hand_Side', 'Support', 'Confidence', 'Lift'])\n",
    "    for i in range(0,len(output_DataFrame)):\n",
    "        if output_DataFrame.iloc[i,0]=='Qualified' or output_DataFrame.iloc[i,1]=='Qualified':\n",
    "            current_dict={'Left_Hand_Side':output_DataFrame.iloc[i,0],'Right_Hand_Side':output_DataFrame.iloc[i,1],\n",
    "                          'Support':output_DataFrame.iloc[i,2], 'Confidence':output_DataFrame.iloc[i,3],\n",
    "                          'Lift':output_DataFrame.iloc[i,4]}\n",
    "            new_df = pd.concat([new_df, pd.DataFrame.from_records([current_dict])])\n",
    "    return new_df\n",
    "def find_qualified_3(output_DataFrame):\n",
    "    new_df=pd.DataFrame(columns = ['Left_Hand_Side', 'Right_Hand_Side', 'Support', 'Confidence', 'Lift'])\n",
    "    for i in range(0,len(output_DataFrame)):\n",
    "        if (len(output_DataFrame.iloc[i,0])==1 and output_DataFrame.iloc[i,0][0]=='Qualified') or (len(output_DataFrame.iloc[i,1])==1 and output_DataFrame.iloc[i,1][0]=='Qualified'):\n",
    "            current_dict={'Left_Hand_Side':output_DataFrame.iloc[i,0],'Right_Hand_Side':output_DataFrame.iloc[i,1],\n",
    "                          'Support':output_DataFrame.iloc[i,2], 'Confidence':output_DataFrame.iloc[i,3],\n",
    "                          'Lift':output_DataFrame.iloc[i,4]}\n",
    "            new_df = pd.concat([new_df, pd.DataFrame.from_records([current_dict])])\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d1c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv('./Alkaline_HER.csv')\n",
    "not_needed_labels_list=['Warning_OER', 'DOI', 'Country', 'Facility', 'Journal_Name', 'IF',\n",
    "       'Indexed_Date', 'Cited_Time', 'Acid_OVP','Neutral_OVP','Remark_Sentence', 'Bug_Note', 'Irregular_Abnormal_Value',\n",
    "       'Irregular_Multiple_Value', 'Irregular_Multiple_Keywords','Warning_OER.1']\n",
    "database=Data.drop(labels=not_needed_labels_list,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e0a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_frequency_set_2and3(database,high_or_low,bar):  \n",
    "    replaced_databse=performance_replace(database,high_or_low,bar)\n",
    "    final_databse=material_replace(replaced_databse,9,59)\n",
    "    # Intializing the list\n",
    "    transacts = []\n",
    "    # populating a list of transactions\n",
    "    for i in range(0, len(final_databse)): \n",
    "        transacts.append(list(final_databse.iloc[i]))\n",
    "    rule = apriori(transactions = transacts, min_support = 0.004, min_confidence = 0.2, min_lift = 1.2, min_length = 2, max_length = 2)\n",
    "    rule_3items = apriori(transactions = transacts, min_support = 0.004, min_confidence = 0.2, min_lift = 1.2, min_length = 3, max_length = 3)\n",
    "\n",
    "    output = list(rule) # returns a non-tabular output\n",
    "    # putting output into a pandas dataframe\n",
    "    results = output\n",
    "    output_DataFrame = pd.DataFrame(inspect(results), columns = ['Left_Hand_Side', 'Right_Hand_Side', 'Support', 'Confidence', 'Lift'])\n",
    "    qualified_DF=find_qualified_2(output_DataFrame)\n",
    "    qualified_DF['Support'] = qualified_DF['Support'].astype(float)\n",
    "    qualified_DF['Confidence'] = qualified_DF['Confidence'].astype(float)\n",
    "    qualified_DF['Lift'] = qualified_DF['Lift'].astype(float)\n",
    "\n",
    "    output_3items = list(rule_3items) # returns a non-tabular output\n",
    "    # putting output into a pandas dataframe\n",
    "    results_3items = output_3items\n",
    "    output_DataFrame_3 = pd.DataFrame(inspect_3(results_3items), columns = ['Left_Hand_Side', 'Right_Hand_Side', 'Support', 'Confidence', 'Lift'])\n",
    "    qualified_DF_3=find_qualified_3(output_DataFrame_3)\n",
    "    qualified_DF_3['Support'] = qualified_DF_3['Support'].astype(float)\n",
    "    qualified_DF_3['Confidence'] = qualified_DF_3['Confidence'].astype(float)\n",
    "    qualified_DF_3['Lift'] = qualified_DF_3['Lift'].astype(float)\n",
    "\n",
    "    return qualified_DF.nlargest(n = 500, columns = 'Lift'),qualified_DF_3.nlargest(n = 500, columns = 'Lift')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0100c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_set_75,three_set_75=get_the_frequency_set_2and3(database,'low',75)\n",
    "two_set_50,three_set_50=get_the_frequency_set_2and3(database,'low',50)\n",
    "two_set_25,three_set_25=get_the_frequency_set_2and3(database,'low',25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf62b644",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_set_25.to_csv('two_set_25'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aeb951",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_set_50.to_csv('two_set_50'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3357532b",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_set_75.to_csv('two_set_75'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537bce5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_set_25.to_csv('three_set_25'+'.csv')\n",
    "three_set_50.to_csv('three_set_50'+'.csv')\n",
    "three_set_75.to_csv('three_set_75'+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20f81d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
